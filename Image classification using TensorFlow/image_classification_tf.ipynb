{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n# Importing data-set of alphabets from kaggle. In this dataset there are 372037 samples of images of size 28*28 each.\ndata = pd.read_csv(\"../input/handwritten_data_785.csv\", encoding = 'utf8')","metadata":{"_uuid":"f102c798d773a016b494c7063bbc97db82500079","_cell_guid":"e3e9775c-d740-4921-9d5f-be49f3bbc30b","execution":{"iopub.status.busy":"2022-06-05T11:46:36.194333Z","iopub.execute_input":"2022-06-05T11:46:36.194655Z","iopub.status.idle":"2022-06-05T11:47:06.600361Z","shell.execute_reply.started":"2022-06-05T11:46:36.19461Z","shell.execute_reply":"2022-06-05T11:47:06.599332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the data frame the first columns is the target values. Since we are predicting alphabets, it has 26 values ranging from 0 to 25. Each of the number relates to its corresponding alphabets. For example, 0 would be A, 1 would be B, and so on. \n\nEach row corresponds to an image, since the image pixel is 28 x 28, we have 28*28 = 784 numbers which is number of columns in each row.\n\nThe reason each image is of 28*28 pixels is because doing computation on this resolution is relatively easy. More resolution means more computation time.","metadata":{}},{"cell_type":"code","source":"target = data.iloc[:,0].values.reshape(-1,1) # reshaping from a tensor to a matrix\nfeatures = data.iloc[:, 1:]","metadata":{"execution":{"iopub.status.busy":"2022-06-05T11:47:06.601488Z","iopub.execute_input":"2022-06-05T11:47:06.60174Z","iopub.status.idle":"2022-06-05T11:47:06.606391Z","shell.execute_reply.started":"2022-06-05T11:47:06.601692Z","shell.execute_reply":"2022-06-05T11:47:06.605652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.shape #labels","metadata":{"execution":{"iopub.status.busy":"2022-06-05T11:47:06.607565Z","iopub.execute_input":"2022-06-05T11:47:06.607962Z","iopub.status.idle":"2022-06-05T11:47:06.62272Z","shell.execute_reply.started":"2022-06-05T11:47:06.607923Z","shell.execute_reply":"2022-06-05T11:47:06.621987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.shape #images","metadata":{"execution":{"iopub.status.busy":"2022-06-05T11:47:06.623862Z","iopub.execute_input":"2022-06-05T11:47:06.624329Z","iopub.status.idle":"2022-06-05T11:47:06.635081Z","shell.execute_reply.started":"2022-06-05T11:47:06.624286Z","shell.execute_reply":"2022-06-05T11:47:06.634542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing dataset\nimport string\ndisplay_features = data.values[:, 1:]\ndisplay_labels = data.values[:,0]\nnr_to_letter = {k:v.upper() for k,v in enumerate(list(string.ascii_lowercase))}\ndisplay_features = display_features.reshape(len(display_features), 28, 28)\nplt.title('Alphabet '+ nr_to_letter[display_labels[4]])\nplt.imshow(display_features[4])","metadata":{"execution":{"iopub.status.busy":"2022-06-05T11:47:06.636094Z","iopub.execute_input":"2022-06-05T11:47:06.636513Z","iopub.status.idle":"2022-06-05T11:47:06.745629Z","shell.execute_reply.started":"2022-06-05T11:47:06.636443Z","shell.execute_reply":"2022-06-05T11:47:06.74506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model below is a simple neural network that uses 3 hidden layers softmax regression.","metadata":{"_uuid":"dc2cfda64f462ee4d1344f956002d179411be7d0","_cell_guid":"8904437e-c85c-4f88-aea2-76c8bc0cf76b"}},{"cell_type":"code","source":"# Using keras which is a neural network library for python\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2022-06-05T11:47:06.746628Z","iopub.execute_input":"2022-06-05T11:47:06.747043Z","iopub.status.idle":"2022-06-05T11:47:08.493339Z","shell.execute_reply.started":"2022-06-05T11:47:06.746999Z","shell.execute_reply":"2022-06-05T11:47:08.49236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting into training and testing\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_train /= 255 #removing rgb channels i.e. converting into b & w\nX_test /= 255\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\ninputs = X_train.shape[1]\nprint(inputs)","metadata":{"_uuid":"6202d98ec5d9fa102d2d1cbe3ecc6dd972152dc3","_cell_guid":"ae28645c-e381-4e73-bb39-7f2cc252cf4f","execution":{"iopub.status.busy":"2022-06-05T11:47:08.494663Z","iopub.execute_input":"2022-06-05T11:47:08.494943Z","iopub.status.idle":"2022-06-05T11:47:17.402078Z","shell.execute_reply.started":"2022-06-05T11:47:08.494893Z","shell.execute_reply":"2022-06-05T11:47:17.401413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Building the model\ndef logit_model(inputs): #inputs are size of image \n    model = Sequential()\n    model.add(Dense(512, activation='relu', input_dim= 28*28)) # Hidden layer 1\n    model.add(Dense(256, activation='relu', input_dim=512)) # Hidden layer 2: Hidden layer 1's nodes are forwaded to this hidden layer 2 as inputs\n    model.add(Dense(128, activation='relu', input_dim=256)) # Hidden layer 3: Hidden layer 2's nodes are passed to hidden layer 3 as inputs\n    model.add(Dense(26, activation='softmax', input_dim=128)) # Output layer : the number of nodes here will be 26 as we have 26 classes for alphabets\n    return model                                                            # and the number of nodes in hidden layer 3 are passed as inputs for output layer","metadata":{"_uuid":"3de87c5cf9e0847954c53b8b41c2cc7d3355dbb6","_cell_guid":"de433a94-86a5-4933-9e1a-1a4bd14980d7","execution":{"iopub.status.busy":"2022-06-05T11:47:17.402957Z","iopub.execute_input":"2022-06-05T11:47:17.40316Z","iopub.status.idle":"2022-06-05T11:47:17.412296Z","shell.execute_reply.started":"2022-06-05T11:47:17.403129Z","shell.execute_reply":"2022-06-05T11:47:17.411551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Input Layer:**\nOnly one layer is input layer. The input layer is specified as a parameter to the first Dense object's constructor which in our case is 28x28 = 784. In case we had 100x100 images input_dim would have been 10,000.\n\n**Hidden Layer:**\nThe number of layers and nodes in hidden layer again are not fixed. You start with few and gradually increase both until you reach a capped accuracy.\n\n**Output Layer:**\nSame as input, output has only one layer and number of nodes here are dependant on the problem for our case it is 26 as we have 26 classes.","metadata":{}},{"cell_type":"markdown","source":"For each example, the model returns a vector of log-odds scores(logarithm of the odds of some event) one for each of the class. So we need to use softmax to convert these scores into probabilities for each class.","metadata":{}},{"cell_type":"code","source":"log_reg = logit_model(inputs)","metadata":{"_uuid":"944a0738292e7e87cc1f1866609b62bef0d05210","_cell_guid":"54617b95-1ef8-4672-8c19-461141525fcb","execution":{"iopub.status.busy":"2022-06-05T11:47:17.41347Z","iopub.execute_input":"2022-06-05T11:47:17.413835Z","iopub.status.idle":"2022-06-05T11:47:17.474168Z","shell.execute_reply.started":"2022-06-05T11:47:17.413778Z","shell.execute_reply":"2022-06-05T11:47:17.473572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_reg.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"_uuid":"fc5cd2a3acace4b9261e8012a4f6a3659dc94409","_cell_guid":"b02341ce-d3a8-46b1-b43b-d9d602dce054","execution":{"iopub.status.busy":"2022-06-05T11:47:17.475254Z","iopub.execute_input":"2022-06-05T11:47:17.475738Z","iopub.status.idle":"2022-06-05T11:47:17.510329Z","shell.execute_reply.started":"2022-06-05T11:47:17.475694Z","shell.execute_reply":"2022-06-05T11:47:17.509642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using sparse categorical cross entropy (as we have many categories similarly for binary we'd use binary cross entropy)","metadata":{}},{"cell_type":"code","source":"model = log_reg.fit(X_train, y_train, epochs = 5, batch_size = 128)","metadata":{"_uuid":"0126ed48090d435970c0a1bbff3875f01d1c7ee2","_cell_guid":"94be65f6-d9ca-452a-92f2-6bbe485b5af3","execution":{"iopub.status.busy":"2022-06-05T11:47:17.511477Z","iopub.execute_input":"2022-06-05T11:47:17.511731Z","iopub.status.idle":"2022-06-05T11:50:32.544759Z","shell.execute_reply.started":"2022-06-05T11:47:17.51168Z","shell.execute_reply":"2022-06-05T11:50:32.544011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for validation data-set we use evaluate function\ntest_score = log_reg.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T11:50:32.545672Z","iopub.execute_input":"2022-06-05T11:50:32.545872Z","iopub.status.idle":"2022-06-05T11:50:39.767937Z","shell.execute_reply.started":"2022-06-05T11:50:32.545842Z","shell.execute_reply":"2022-06-05T11:50:39.766933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Test cost of unseen sample: ' + str(test_score[0]))\nprint('Test cost of unseen sample: ' + str(test_score[1]))","metadata":{"_uuid":"34344027cf96fa4b5163d41c1cd20be064fb5129","execution":{"iopub.status.busy":"2022-06-05T11:50:39.769294Z","iopub.execute_input":"2022-06-05T11:50:39.76962Z","iopub.status.idle":"2022-06-05T11:50:39.775315Z","shell.execute_reply.started":"2022-06-05T11:50:39.769566Z","shell.execute_reply":"2022-06-05T11:50:39.774565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(len(model.history['loss'])), model.history['loss'], label='Training cost')\nplt.title('Training Cost')\n","metadata":{"_uuid":"b5e976efb25ae11c51bc60db1b251886d5dc46fd","execution":{"iopub.status.busy":"2022-06-05T11:50:39.776576Z","iopub.execute_input":"2022-06-05T11:50:39.776879Z","iopub.status.idle":"2022-06-05T11:50:40.016561Z","shell.execute_reply.started":"2022-06-05T11:50:39.776825Z","shell.execute_reply":"2022-06-05T11:50:40.015631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(len(model.history['acc'])), model.history['acc'], 'r', label='Training Accuracy')\nplt.title('Training Accuracy')","metadata":{"_uuid":"2220dcd8c1af8a73c2dd1c705559b62bc610a6dc","execution":{"iopub.status.busy":"2022-06-05T11:50:40.017934Z","iopub.execute_input":"2022-06-05T11:50:40.018269Z","iopub.status.idle":"2022-06-05T11:50:40.138335Z","shell.execute_reply.started":"2022-06-05T11:50:40.018207Z","shell.execute_reply":"2022-06-05T11:50:40.137518Z"},"trusted":true},"execution_count":null,"outputs":[]}]}